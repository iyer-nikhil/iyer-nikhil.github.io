<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Nick S. Iyer</title>
    <description>A journey through data science</description>
    <link>http://localhost:4000/</link>
    <atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Mon, 27 Nov 2017 16:43:29 -0500</pubDate>
    <lastBuildDate>Mon, 27 Nov 2017 16:43:29 -0500</lastBuildDate>
    <generator>Jekyll v3.5.2</generator>
    
      <item>
        <title>Zillow Prize: Predicting Real Estate</title>
        <description>&lt;p&gt;When I initially joined a data science bootcamp, my dream was to compete in a &lt;a href=&quot;https://www.kaggle.com/&quot;&gt;Kaggle&lt;/a&gt; competition. For those of you that are unfamiliar with what that is, &lt;a href=&quot;https://www.kaggle.com/&quot;&gt;Kaggle&lt;/a&gt; hosts data science competitions for prizes if you are able to score the lowest on a particular benchmark given.&lt;/p&gt;

&lt;p&gt;The grades for the competition allow you to compete against others for a chance at some serious prize money and Zillow just put out a $1 million dollar prize for someone who could use variables on a given property and beat their current estimate algorithm on pricing.&lt;/p&gt;

&lt;p&gt;In order to get there though, they have a few barriers to entry:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;In order to compete in that leg, there is an initial leg of the tournament where only the top 100 advance. The goal of this first leg is to estimate how far off Zillow is at computing an estimate for a given property.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Half the data hasn’t even come out yet. They released 2016 data but ask you to predict the remaining months of 2017 - October, November, and December, for estimates and relative sale prices and will only release this at the beginning of October&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Once that is completed, if your model turns out to be in the top 100, then you have yourself a shot at their $1 million dollar prize!&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For starters, I had to feature engineer something that would put me in a position to succeed. That started with examining certain features like the type of property below:&lt;/p&gt;

&lt;p&gt;&lt;!-- ![edit](/static/assets/img/landing//3steps/Image-1.jpg) --&gt;
   &lt;img src=&quot;/static/assets/img/landing//3steps/Image-1.jpg&quot; width=&quot;70%&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;On the left you can see how well Zillow was able to close the gap between their estimate and the final sale price of a home. Obviously they aren’t the best with every home, or they wouldn’t have this competition in the first place.
You can see as part of that map that areas in green tend to be pretty accurate, but the area in yellow that is boxed in red happens to be a blob where their estimate tends to be weak and be very far from estimating the final sale price correctly.
By doing some feature engineering I was able to see that the type of property became a huge indicator of whether or not an estimate was possible, as shown by the map on the right. Most of the properties tend to be single family residentials, but you will notice that for multi-unit housing, the Zillow estimate just does not do a good job in capturing the final sale price.&lt;/p&gt;

&lt;p&gt;After weighting that with some level of significance in running a model (XGBoost) I was able to get into the top 800 of the competition while it was still around ~2500 people entered:&lt;/p&gt;

&lt;p&gt;&lt;!-- ![edit](/static/assets/img/landing//3steps/800thplace.png) --&gt;
   &lt;img src=&quot;/static/assets/img/landing//3steps/800thplace.png&quot; width=&quot;70%&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;I did do some slight tweaking to the model’s parameters and also found an interesting spot to potentially bifurcate the data. This is in the type of zoning for the property seen here:&lt;/p&gt;

&lt;p&gt;&lt;!-- ![edit](/static/assets/img/landing//3steps/image5.png) --&gt;
   &lt;img src=&quot;/static/assets/img/landing//3steps/image5.png&quot; width=&quot;70%&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;By using the type of zoning, I could see that those properties with pool zoning would vastly differ in sale price from the estimate. It didn’t just have to do with geographic location and I was better able to isolate this in my model.&lt;/p&gt;

&lt;p&gt;The biggest breakthrough came with running an average of various models with different weightings and node parameters. Using a combination of XGBoost and LightGBM by stacking (aka using in conjunction), I was able to bounce even higher in the competition to where I am today. The basic principle is below:&lt;/p&gt;

&lt;p&gt;&lt;!-- ![edit](/static/assets/img/landing//3steps/image3.png) --&gt;
   &lt;img src=&quot;/static/assets/img/landing//3steps/image3.png&quot; width=&quot;70%&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This is a basic diagram for stacking. As you can see, by taking the training data, passing it through models, and taking various weights of those models, we can produce a better overall predictor which vaulted me to the spot I am at today.
The exact combination of the models I did use are as follows:&lt;/p&gt;

&lt;p&gt;&lt;!-- ![edit](/static/assets/img/landing//3steps/image4.png) --&gt;
   &lt;img src=&quot;/static/assets/img/landing//3steps/image4.png&quot; width=&quot;70%&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;So far got into the &lt;a href=&quot;https://www.kaggle.com/nicksiyer&quot;&gt;top 11%&lt;/a&gt;! Hope to post more about other kaggle competitions here soon!&lt;/p&gt;
</description>
        <pubDate>Fri, 15 Sep 2017 00:00:00 -0400</pubDate>
        <link>http://localhost:4000/python/2017/09/15/Zillow-Competition.html</link>
        <guid isPermaLink="true">http://localhost:4000/python/2017/09/15/Zillow-Competition.html</guid>
        
        <category>Python</category>
        
        <category>Data</category>
        
        <category>Boosting</category>
        
        
        <category>Python</category>
        
      </item>
    
      <item>
        <title>Creating This Website</title>
        <description>&lt;p&gt;Everyone wants to have a personal website, you can display your infomation to public. Fortunately, its pretty easy
with Jekyll and github pages. I designed this website by taking a previous website design that I liked, used some elements of it
but changed most of it through trial &amp;amp; error + testing.&lt;/p&gt;

&lt;p&gt;Most of the configurations of websites exist in the config.yml page of Jekyll, but this particular project was all over the place and definitely required
a lot more than that. But a couple of pointers for those trying their skills at making a website:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Use finder to find various instances of words scattered throughout the css, including the names of pictures and fonts. This will help you locate exactly where you need to edit style changes in order to push it to your website&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Push changes to your github repository and view your website, done!&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Thanks for visiting!&lt;/p&gt;

</description>
        <pubDate>Thu, 07 Sep 2017 00:00:00 -0400</pubDate>
        <link>http://localhost:4000/html/2017/09/07/Creating-this-website.html</link>
        <guid isPermaLink="true">http://localhost:4000/html/2017/09/07/Creating-this-website.html</guid>
        
        <category>Jekyll</category>
        
        
        <category>HTML</category>
        
      </item>
    
      <item>
        <title>Predicting Stock Price Using Key Statistics</title>
        <description>&lt;p&gt;Not having a lot of experience working in finance, I wanted to know what exactly went into the pricing of a stock. During a trading day, a given stock will go up or down depending on the supply and demand of shares, and is always moving towards an optimal price that factors in the value of a company dependent on what investors feel it is worth.&lt;/p&gt;

&lt;p&gt;But removing for news and sticking solely to the quantitative fundamentals, the question was, “could I use a regressive model to judge if a stock is over or underpriced in the market?” Obviously this is a very naive approach that does not factor main factors such as recent news as well as any earnings outlook that may have been priced in. But I decided to give it a shot and see what happened.&lt;/p&gt;

&lt;p&gt;By setting up a scraper to parse Yahoo Finance key statistics into a .json file, I took a look at the following metrics of a sample stock :&lt;/p&gt;

&lt;p&gt;&lt;!-- ![edit](/static/assets/img/landing//3steps/stats2.png) --&gt; &lt;!-- ![edit](/static/assets/img/landing//3steps/stats1.png) --&gt; &lt;!-- ![edit](/static/assets/img/landing//3steps/stats2.png) --&gt; &lt;!-- ![edit](/static/assets/img/landing//3steps/stats1.png) --&gt; 
  &lt;img src=&quot;/static/assets/img/landing//3steps/stats2.png&quot; width=&quot;23%&quot; /&gt; &lt;img src=&quot;/static/assets/img/landing//3steps/stats1.png&quot; width=&quot;23%&quot; /&gt; &lt;img src=&quot;/static/assets/img/landing//3steps/stats2.png&quot; width=&quot;23%&quot; /&gt; &lt;img src=&quot;/static/assets/img/landing//3steps/stats1.png&quot; width=&quot;23%&quot; /&gt;&lt;/p&gt;

</description>
        <pubDate>Sun, 23 Jul 2017 00:00:00 -0400</pubDate>
        <link>http://localhost:4000/python/2017/07/23/Using-Stock-Fundamentals-To-Predict-Stock-Price.html</link>
        <guid isPermaLink="true">http://localhost:4000/python/2017/07/23/Using-Stock-Fundamentals-To-Predict-Stock-Price.html</guid>
        
        <category>Python</category>
        
        <category>Data</category>
        
        <category>Scrapy</category>
        
        <category>Finance</category>
        
        <category>Linear Regression</category>
        
        
        <category>Python</category>
        
      </item>
    
      <item>
        <title>NYC Open Data: Examining MTA Turnstile Data</title>
        <description>&lt;p&gt;NYC Open Data puts out a lot of neat information online. One of these pieces is MTA data that shows how many people go through various turnstiles across NYC’s boroughs. I thought it was a cool EDA to check out and especially the subway line that is relatively new to the city and one close to my heart: the 2nd Ave Q line.&lt;/p&gt;

&lt;p&gt;This line is relatively new, only open as of January 1st, 2017 for parts that go through 72nd and 96th street. After loving this area so much, having friends who live in this area as well, I thought it would be cool to check out exactly how many people go in and out of this area.&lt;/p&gt;

&lt;p&gt;As you can see from the image below, it is relatively consistent goings for turnstiles for different days of the week:&lt;/p&gt;

&lt;p&gt;&lt;!-- ![edit](/static/assets/img/landing//3steps/img1g2.jpg) --&gt;
   &lt;img src=&quot;/static/assets/img/landing//3steps/img1g2.jpg&quot; width=&quot;70%&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;As you can see from these 4 weeks of data that I obtained, they follow a similar pattern, with ridership relatively slow on mondays, picking up through midweek, and dropping off by the weekend. It is fascinating to see that for some weeks, there is a jump from Saturday into Sunday but for some weeks, there is a dip. This might be due to attractions or certain weekend events that restaurants have in the area. I’d also like to see how street fairs in the area could potentially impact this graph.&lt;/p&gt;

&lt;p&gt;Here is another visual in the form of a bar graph to give you a much better side by side comparison of days in different weeks:&lt;/p&gt;

&lt;p&gt;&lt;!-- ![Bar graph of subway entries for 86th St](/static/assets/img/landing//3steps/img1g3.jpg) --&gt;
   &lt;img src=&quot;/static/assets/img/landing//3steps/img1g3.jpg&quot; width=&quot;70%&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;One interesting thing to note is that these are just entries into the subway and not exits. Why did I choose to leave exits alone? Well its because even when looking at multiple stations, the entries and exits on a weekly basis do not match at all.&lt;/p&gt;

&lt;p&gt;&lt;!-- ![edit](/static/assets/img/landing//3steps/img1g4.jpg) --&gt;
   &lt;img src=&quot;/static/assets/img/landing//3steps/img1g4.jpg&quot; width=&quot;70%&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;That’s because in some cases, people use the emergency exits on the turnstiles, which do not count the number of people. So having the entries is for the most part accurate because that barrier is set. Using exits would not be doing the data justice.&lt;/p&gt;

&lt;p&gt;Thank you for listening to my intro EDA for MTA Turnstiles. If you want to check out my &lt;a href=&quot;https://github.com/nicksiyer/mta_turnstiles&quot;&gt;GitHub&lt;/a&gt; please feel free! This is my first project working with data and I urge you to check out my other projects that cover more extensively machine learning tools that I learned throughout the Metis program.&lt;/p&gt;
</description>
        <pubDate>Tue, 11 Jul 2017 00:00:00 -0400</pubDate>
        <link>http://localhost:4000/python/2017/07/11/Examining-MTA-Turnstile-Data.html</link>
        <guid isPermaLink="true">http://localhost:4000/python/2017/07/11/Examining-MTA-Turnstile-Data.html</guid>
        
        <category>Python</category>
        
        <category>Data</category>
        
        <category>Pandas</category>
        
        
        <category>Python</category>
        
      </item>
    
  </channel>
</rss>
